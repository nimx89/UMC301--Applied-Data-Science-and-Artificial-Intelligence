{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9757dda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0f611",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/iisc-umc-301-kaggle-competition-1/train.csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/iisc-umc-301-kaggle-competition-1/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/iisc-umc-301-kaggle-competition-1/sample_submission.csv\")\n",
    "\n",
    "train.rename(columns={'audio_valence':'valence','audio_mode':'mode'}, inplace=True)\n",
    "test.rename(columns={'audio_valence':'valence','audio_mode':'mode'}, inplace=True)\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test_ids = test.pop('id')\n",
    "\n",
    "# predictors/target  (raw, no scaling or imputation)\n",
    "X = train.drop('song_popularity', axis=1)\n",
    "y = train['song_popularity']\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a856551",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cross-validation helper\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scale_pos_weight = (y == 0).sum() / (y == 1).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b2f81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Optuna: XGBoost\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "        \"n_estimators\": 800,\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    oof = np.zeros(len(X))\n",
    "    for tr, val in skf.split(X, y):\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X.iloc[tr], y.iloc[tr],\n",
    "                  eval_set=[(X.iloc[val], y.iloc[val])],\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=False)\n",
    "        oof[val] = model.predict_proba(X.iloc[val])[:, 1]\n",
    "    return roc_auc_score(y, oof)\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"maximize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "\n",
    "xgb_params = {**study_xgb.best_params,\n",
    "              \"objective\": \"binary:logistic\",\n",
    "              \"eval_metric\": \"auc\",\n",
    "              \"n_estimators\": 800,\n",
    "              \"scale_pos_weight\": scale_pos_weight,\n",
    "              \"tree_method\": \"gpu_hist\",\n",
    "              \"random_state\": 42,\n",
    "              \"n_jobs\": -1}\n",
    "\n",
    "# Optuna: CatBoost\n",
    "def objective_cat(trial):\n",
    "    params = {\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.05),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 6),\n",
    "        \"iterations\": 800,\n",
    "        \"task_type\": \"GPU\",\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": False\n",
    "    }\n",
    "    oof = np.zeros(len(X))\n",
    "    for tr, val in skf.split(X, y):\n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        model.fit(X.iloc[tr], y.iloc[tr],\n",
    "                  eval_set=(X.iloc[val], y.iloc[val]),\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=False)\n",
    "        oof[val] = model.predict_proba(X.iloc[val])[:, 1]\n",
    "    return roc_auc_score(y, oof)\n",
    "\n",
    "study_cat = optuna.create_study(direction=\"maximize\")\n",
    "study_cat.optimize(objective_cat, n_trials=30)\n",
    "\n",
    "cat_params = {**study_cat.best_params,\n",
    "              \"loss_function\": \"Logloss\",\n",
    "              \"eval_metric\": \"AUC\",\n",
    "              \"iterations\": 800,\n",
    "              \"task_type\": \"GPU\",\n",
    "              \"random_seed\": 42,\n",
    "              \"verbose\": False}\n",
    "\n",
    "print(\"Best XGB params:\", xgb_params)\n",
    "print(\"Best CAT params:\", cat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c1309",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Bagging: 40 XGB + 40 CatBoost\n",
    "N_XGB = 40\n",
    "N_CAT = 40\n",
    "test_preds = np.zeros(len(X_test))\n",
    "oof_preds = np.zeros(len(X))\n",
    "\n",
    "# Clean param dicts to avoid duplicate keys\n",
    "xgb_params_clean = {k: v for k, v in xgb_params.items()\n",
    "                    if k not in [\"random_state\"]}\n",
    "cat_params_clean = {k: v for k, v in cat_params.items()\n",
    "                    if k not in [\"random_seed\", \"verbose\"]}\n",
    "\n",
    "# Train 40 XGB\n",
    "for seed in range(N_XGB):\n",
    "    model = xgb.XGBClassifier(**xgb_params_clean, random_state=seed)\n",
    "    model.fit(X, y, verbose=False)\n",
    "    oof_preds += model.predict_proba(X)[:, 1] / (N_XGB + N_CAT)\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / (N_XGB + N_CAT)\n",
    "\n",
    "# Train 40 CatBoost\n",
    "for seed in range(N_CAT):\n",
    "    model = cb.CatBoostClassifier(**cat_params_clean,\n",
    "                                  random_seed=seed,\n",
    "                                  verbose=False)\n",
    "    model.fit(X, y)\n",
    "    oof_preds += model.predict_proba(X)[:, 1] / (N_XGB + N_CAT)\n",
    "    test_preds += model.predict_proba(X_test)[:, 1] / (N_XGB + N_CAT)\n",
    "\n",
    "print(\"OOF AUC (bagged 40 models):\", roc_auc_score(y, oof_preds))\n",
    "\n",
    "submission[\"song_popularity\"] = test_preds\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… submission.csv written\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
